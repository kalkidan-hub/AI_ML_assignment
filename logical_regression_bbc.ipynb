{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file, we are going to implement the logistic regression algorithm on the bbc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from cmath import e\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Perform additional preprocessing if needed\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets extract the data from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = 'bbc'\n",
    "subfolders = ['business', 'entertainment', 'sport', 'politics', 'tech']\n",
    "word_dict = defaultdict(list)\n",
    "categories_count = defaultdict(int)\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for subfolder in subfolders:\n",
    "    folder_path = os.path.join(parent_folder, subfolder)\n",
    "    files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "\n",
    "    categories_count[subfolder] += len(files)\n",
    "\n",
    "    for file_path in files[:100]:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            train_texts.append(content)\n",
    "            train_labels.append(subfolder)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labeling and vectorization of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19770)\t6\n",
      "  (0, 8875)\t1\n",
      "  (0, 22937)\t9\n",
      "  (0, 3662)\t3\n",
      "  (0, 11120)\t2\n",
      "  (0, 21811)\t2\n",
      "  (0, 22711)\t15\n",
      "  (0, 12570)\t2\n",
      "  (0, 10886)\t1\n",
      "  (0, 8876)\t2\n",
      "  (0, 11033)\t1\n",
      "  (0, 23490)\t1\n",
      "  (0, 18584)\t1\n",
      "  (0, 9738)\t2\n",
      "  (0, 17391)\t1\n",
      "  (0, 4901)\t2\n",
      "  (0, 20139)\t1\n",
      "  (0, 22167)\t2\n",
      "  (0, 10849)\t1\n",
      "  (0, 9597)\t2\n",
      "  (0, 21750)\t2\n",
      "  (0, 18519)\t1\n",
      "  (0, 2917)\t1\n",
      "  (0, 11498)\t1\n",
      "  (0, 4159)\t2\n",
      "  :\t:\n",
      "  (1499, 12221)\t1\n",
      "  (1499, 17235)\t1\n",
      "  (1499, 12385)\t12\n",
      "  (1499, 22549)\t6\n",
      "  (1499, 3266)\t1\n",
      "  (1499, 7102)\t1\n",
      "  (1499, 10387)\t4\n",
      "  (1499, 1810)\t1\n",
      "  (1499, 18317)\t1\n",
      "  (1499, 10068)\t1\n",
      "  (1499, 7736)\t1\n",
      "  (1499, 22497)\t1\n",
      "  (1499, 13700)\t1\n",
      "  (1499, 9240)\t1\n",
      "  (1499, 4195)\t1\n",
      "  (1499, 12148)\t1\n",
      "  (1499, 9374)\t1\n",
      "  (1499, 14877)\t1\n",
      "  (1499, 1819)\t1\n",
      "  (1499, 3895)\t1\n",
      "  (1499, 10826)\t1\n",
      "  (1499, 23662)\t1\n",
      "  (1499, 17847)\t1\n",
      "  (1499, 15397)\t1\n",
      "  (1499, 5902)\t1\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "# print(X_train)\n",
    "label_mapping = {'business': 0, 'entertainment': 1, 'sport': 2, 'politics': 3, 'tech': 4}\n",
    "train_labels_numeric = [label_mapping[label] for label in train_labels]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def sigmoid(self,z):\n",
    "        sig = 1/(1+e**(-z))\n",
    "        return sig\n",
    "\n",
    "def train_logistic_regression(X, y, learning_rate, num_iterations):\n",
    "    num_samples, num_features = X.shape\n",
    "    weights = [0.0] * num_features\n",
    "    bias = 0.0\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Compute the predictions\n",
    "        scores = [bias + np.dot(X[i], weights) for i in range(num_samples)]\n",
    "        y_pred = sigmoid(scores)\n",
    "\n",
    "        # Update the weights and bias using gradient descent\n",
    "        error = [y_pred[i] - y[i] for i in range(num_samples)]\n",
    "        gradient = np.dot(X.T, error)\n",
    "        weights -= learning_rate * gradient\n",
    "        bias -= learning_rate * sum(error)\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "def predict(X, weights, bias):\n",
    "    scores = [bias + np.dot(X[i], weights) for i in range(X.shape[0])]\n",
    "    y_pred = [1 if score > 0.5 else 0 for score in scores]\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_predictions = sum([1 for i in range(len(y_true)) if y_true[i] == y_pred[i]])\n",
    "    total_samples = len(y_true)\n",
    "    acc = correct_predictions / total_samples\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_iterations = 100\n",
    "\n",
    "weights, bias = train_logistic_regression(X_train, train_labels_numeric, learning_rate, num_iterations)\n",
    "\n",
    "y_pred = predict(X_train, weights, bias)\n",
    "\n",
    "acc = accuracy(train_labels_numeric, y_pred)\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
